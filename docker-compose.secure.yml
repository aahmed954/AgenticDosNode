version: '3.8'

services:
  # AI Executor with maximum security
  ai-executor:
    image: ai-executor:secure
    container_name: ai-executor-secure
    hostname: ai-executor
    security_opt:
      - no-new-privileges:true
      - seccomp:seccomp-ai.json
      - apparmor:ai-executor
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETGID
      - SETUID
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100M
      - /var/run:noexec,nosuid,size=10M
    volumes:
      - type: bind
        source: ./sandbox
        target: /sandbox
        read_only: false
        bind:
          propagation: private
      - type: bind
        source: ./seccomp-ai.json
        target: /seccomp-ai.json
        read_only: true
    environment:
      - NODE_ENV=production
      - SECURE_MODE=true
      - MAX_EXECUTION_TIME=30
      - MAX_MEMORY=512M
    networks:
      ai_isolated:
        ipv4_address: 172.28.1.10
    ulimits:
      nproc: 50
      nofile:
        soft: 1024
        hard: 2048
      memlock:
        soft: -1
        hard: -1
    mem_limit: 2g
    memswap_limit: 2g
    cpu_quota: 50000
    cpu_period: 100000
    pids_limit: 100
    restart: on-failure:3
    healthcheck:
      test: ["CMD", "pgrep", "python3"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=ai-executor"

  # Vector Database (Milvus) with security
  milvus-secure:
    image: milvusdb/milvus:latest
    container_name: milvus-secure
    hostname: milvus
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
      - CHOWN
      - SETUID
      - SETGID
    volumes:
      - type: volume
        source: milvus_data
        target: /var/lib/milvus
      - type: bind
        source: ./milvus-config-secure.yaml
        target: /milvus/configs/milvus.yaml
        read_only: true
      - type: bind
        source: ./certs/milvus
        target: /certs
        read_only: true
    environment:
      - MILVUS_USE_TLS=true
      - MILVUS_SERVER_CERT=/certs/server.pem
      - MILVUS_SERVER_KEY=/certs/server.key
      - MILVUS_CA_CERT=/certs/ca.pem
      - MILVUS_AUTH_ENABLED=true
    networks:
      ai_isolated:
        ipv4_address: 172.28.1.20
    ports:
      - "127.0.0.1:19530:19530"  # Only bind to localhost
    mem_limit: 4g
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # n8n Workflow Automation with security
  n8n-secure:
    image: n8nio/n8n:latest
    container_name: n8n-secure
    hostname: n8n
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETUID
      - SETGID
    volumes:
      - type: volume
        source: n8n_data
        target: /home/node/.n8n
      - type: bind
        source: ./n8n-config
        target: /home/node/.n8n/config
        read_only: true
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${N8N_USER}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_PASSWORD}
      - N8N_HOST=0.0.0.0
      - N8N_PORT=5678
      - N8N_PROTOCOL=https
      - N8N_SSL_KEY=/home/node/.n8n/config/server.key
      - N8N_SSL_CERT=/home/node/.n8n/config/server.crt
      - WEBHOOK_URL=https://n8n.local.mesh
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
      - N8N_USER_FOLDER=/home/node/.n8n
      - EXECUTIONS_PROCESS=main
      - N8N_LOG_LEVEL=warn
      - N8N_METRICS=true
    networks:
      ai_isolated:
        ipv4_address: 172.28.1.30
    ports:
      - "127.0.0.1:5678:5678"  # Only bind to localhost
    mem_limit: 2g
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5678/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"

  # Redis for session management (secure)
  redis-secure:
    image: redis:7-alpine
    container_name: redis-secure
    hostname: redis
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --appendfsync everysec
      --tcp-backlog 511
      --tcp-keepalive 300
      --timeout 0
      --protected-mode yes
      --port 0
      --tls-port 6379
      --tls-cert-file /tls/server.crt
      --tls-key-file /tls/server.key
      --tls-ca-cert-file /tls/ca.crt
      --tls-auth-clients yes
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - SETUID
      - SETGID
    volumes:
      - type: volume
        source: redis_data
        target: /data
      - type: bind
        source: ./certs/redis
        target: /tls
        read_only: true
    networks:
      ai_isolated:
        ipv4_address: 172.28.1.40
    mem_limit: 512m
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "--tls", "--cert", "/tls/client.crt", "--key", "/tls/client.key", "--cacert", "/tls/ca.crt", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Vault for secret management
  vault:
    image: hashicorp/vault:latest
    container_name: vault-secure
    hostname: vault
    cap_add:
      - IPC_LOCK
    security_opt:
      - no-new-privileges:true
    environment:
      - VAULT_ADDR=https://127.0.0.1:8200
      - VAULT_API_ADDR=https://127.0.0.1:8200
      - VAULT_CLUSTER_ADDR=https://127.0.0.1:8201
    volumes:
      - type: volume
        source: vault_data
        target: /vault/data
      - type: bind
        source: ./vault-config.hcl
        target: /vault/config/vault.hcl
        read_only: true
      - type: bind
        source: ./certs/vault
        target: /vault/tls
        read_only: true
    networks:
      ai_isolated:
        ipv4_address: 172.28.1.50
    ports:
      - "127.0.0.1:8200:8200"
    command: server
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "vault", "status", "-tls-skip-verify"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # WAF/Reverse Proxy with ModSecurity
  waf-proxy:
    image: owasp/modsecurity-crs:nginx
    container_name: waf-proxy
    hostname: waf
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
      - CHOWN
      - SETUID
      - SETGID
    volumes:
      - type: bind
        source: ./nginx-secure.conf
        target: /etc/nginx/nginx.conf
        read_only: true
      - type: bind
        source: ./modsecurity
        target: /etc/modsecurity.d
        read_only: true
      - type: bind
        source: ./certs/nginx
        target: /etc/nginx/certs
        read_only: true
    environment:
      - PARANOIA=2
      - ANOMALY_INBOUND=5
      - ANOMALY_OUTBOUND=4
      - BACKEND=http://ai-executor:8080
    networks:
      ai_isolated:
        ipv4_address: 172.28.1.2
      tailscale_network:
        ipv4_address: 172.29.1.2
    ports:
      - "443:443"
      - "80:80"
    mem_limit: 1g
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"

volumes:
  milvus_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/ai-data/milvus
  n8n_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/ai-data/n8n
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/ai-data/redis
  vault_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/ai-data/vault

networks:
  ai_isolated:
    name: ai_isolated
    driver: bridge
    driver_opts:
      com.docker.network.bridge.name: br-ai-isolated
    ipam:
      driver: default
      config:
        - subnet: 172.28.0.0/16
          gateway: 172.28.0.1
    internal: true  # No external connectivity

  tailscale_network:
    name: tailscale_network
    driver: bridge
    driver_opts:
      com.docker.network.bridge.name: br-tailscale
    ipam:
      driver: default
      config:
        - subnet: 172.29.0.0/16
          gateway: 172.29.0.1